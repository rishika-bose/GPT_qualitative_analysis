{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e89413ac-cf20-4854-8448-6d0dca996f24",
   "metadata": {},
   "source": [
    "# Qualitative Analysis with GPT - trying different prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65fbce02-f51b-4b7f-b9bc-2547201109f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8b864d4-748a-4202-a691-1f470f011c94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of comments: 2776\n"
     ]
    }
   ],
   "source": [
    "#openai.api_key = open(\"../org_openai_key.txt\").read()\n",
    "openai.api_key = open(\"../openai_key.txt\").read()\n",
    "all_dat = pd.read_csv(\"../data/data_preprocessed.csv\")\n",
    "print(\"Total number of comments:\", len(all_dat[\"Comment\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ba1a6f3-1718-4410-b13b-392a249a5275",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Subsets of data for testing\n",
    "dat_10 = all_dat.iloc[0:10]\n",
    "dat_30 = all_dat.iloc[0:30]\n",
    "dat_100 = all_dat.iloc[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9fa00ef-b069-4667-81cc-def37f813e50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Read the different pieces of text that can be used to prompt the model\n",
    "role_prompt = open(\"./prompts/role_prompt.txt\").read()\n",
    "simple_context_prompt = open(\"./prompts/simple_context_prompt.txt\").read()\n",
    "detailed_context_prompt = open(\"./prompts/detailed_context_prompt.txt\").read()\n",
    "example_short = open(\"./prompts/example_code_numbers.txt\").read()\n",
    "example_long = open(\"./prompts/example_correct-codes_descriptions.txt\").read()\n",
    "story_prompt = open(\"./prompts/story_prompt.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b50da6f9-09a8-4b4f-bcfe-af8a00ba4c4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function which takes a prompt (which will be a combination of those above), a comment, and max tokens for response\n",
    "# Returns the model's completion text\n",
    "# consider: make the engine a param as well?\n",
    "# consider: change to 'Top codes:' instead of 'Codes:' to encourage considering multiple\n",
    "def code_this(prompt_list, comment, max_tokens):\n",
    "    prompt = prompt_list+\"Comment:\"+comment+\"Codes:\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-ada-001\", #change\n",
    "        prompt=prompt,\n",
    "        temperature=0,\n",
    "        max_tokens=max_tokens \n",
    "    )\n",
    "    return response[\"choices\"][0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef1510db-050c-4a38-ad16-f3d24523c51c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Function that calls the above for each comment in a list of comments, and saves an excel file with responses for each comment\n",
    "#Returns nothing\n",
    "def get_responses(data, prompt_list, max_tokens, filename):\n",
    "    response_dict = {}\n",
    "    for c in data[\"Comment\"]:\n",
    "        response_dict[c] = code_this(prompt_list, c, max_tokens)      \n",
    "\n",
    "    response_df = pd.DataFrame(response_dict.items(), columns=['Comment', 'Response'])\n",
    "    response_df.to_excel(\"./outputs/\"+filename+\".xlsx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dc07ee-a7f3-4fd1-9f79-40eaa2bfbf47",
   "metadata": {},
   "source": [
    "Trying out prompting method with 10 comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd782d96-0a4b-4802-9220-cf359fae97ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#edit to include max_tokens\n",
    "\n",
    "#prompt_list_1 = simple_context_prompt\n",
    "#simple_context_only = {}\n",
    "#for c in dat_10[\"Comment\"]:\n",
    "#    simple_context_only[c] = code_this(prompt_list_1, c)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8ddd5a53-662a-45bb-aecd-bca03336d78b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test_10 = pd.DataFrame(simple_context_only, index=[0]).transpose().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f674bf5f-3bb2-4915-a291-2aae63d06762",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test_10.to_csv(\"./outputs/testing_10maxtokens_simplecontextprompt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cba97f80-49f6-4328-b9cd-2a3a9cddf47b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He is already sociable he doesn't need the pill.</td>\n",
       "      <td>\\n30\\tHe is already sociable he doesn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John didn't have a problem - he was just fine ...</td>\n",
       "      <td>\\n2 NOT COMfortable with him taking the pill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If John was quite comfortable with how social ...</td>\n",
       "      <td>1-3\\n1 \\nNot comfortable with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It seems like he's a pretty well-adjusted guy ...</td>\n",
       "      <td>\\n30\\t relieved that he's not being candy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John is healthy and is not suffering from any ...</td>\n",
       "      <td>\\n1 Not comfortable with him taking the pill -</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Unnamed: 0  \\\n",
       "0   He is already sociable he doesn't need the pill.   \n",
       "1  John didn't have a problem - he was just fine ...   \n",
       "2  If John was quite comfortable with how social ...   \n",
       "3  It seems like he's a pretty well-adjusted guy ...   \n",
       "4  John is healthy and is not suffering from any ...   \n",
       "\n",
       "                                                0  \n",
       "0           \\n30\\tHe is already sociable he doesn  \n",
       "1    \\n2 NOT COMfortable with him taking the pill  \n",
       "2                   1-3\\n1 \\nNot comfortable with  \n",
       "3       \\n30\\t relieved that he's not being candy  \n",
       "4  \\n1 Not comfortable with him taking the pill -  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Commented out code above to make this re-runnable\n",
    "test_10 = pd.read_csv(\"./outputs/testing_10maxtokens_simplecontextprompt.csv\")\n",
    "test_10.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836f965c-4ca6-4a4d-9ada-8f995c71d7b6",
   "metadata": {},
   "source": [
    "Looks like it's working, though max_tokens=10 is too low. The function was edited to take max_tokens as a param at this point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01880169-6bac-4543-837d-fcebb4cc0ec1",
   "metadata": {},
   "source": [
    "Below, I will try 4 different prompt combinations with the 30-comment dataset. I will use the best performing prompt and apply it to the larger 100-comment dataset.\n",
    "\n",
    "Longer and more detailed prompts may lead to better performance, but if shorter prompts can give similar performance they may be the better choice. Looking at different combinations can also help in understanding which parts of the final prompt are contributing to the performance.\n",
    "\n",
    "The coding framework is 324 words, or around 432 tokens, long. If the model listed every single code, it would require around that many tokens; ideally it would list fewer. The max token parameter is set at 450 to allow it to list all of them if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539bdb39-70bf-4f32-be06-4ea9b1759359",
   "metadata": {},
   "outputs": [],
   "source": [
    "#consider adding long/short examples as well?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afd2118-649d-4e7a-9508-21f3b4eb4b8c",
   "metadata": {},
   "source": [
    "Different combinations tried out below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee09c2bb-deb8-4152-b155-fb818cb1399e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Role prompt + simple context prompt\n",
    "prompt_list_2 = role_prompt + simple_context_prompt\n",
    "get_responses(dat_30, prompt_list_2, 450, \"role_simple_context_30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "311c6a41-c357-4ce0-8a06-91723cffa0bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Role prompt + simple context prompt + example\n",
    "prompt_list_3 = role_prompt + simple_context_prompt + example_long\n",
    "get_responses(dat_30, prompt_list_3, 450, \"role_simple_context_ex_30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cfa38867-f56e-487b-b236-63602bfbe8e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Role prompt + detailed context prompt\n",
    "prompt_list_4 = role_prompt + detailed_context_prompt \n",
    "get_responses(dat_30, prompt_list_4, 450, \"role_detailed_context_30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83c71182-3648-4dcd-9c97-d24165d74172",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Role prompt + detailed context prompt + example\n",
    "prompt_list_5 = role_prompt + detailed_context_prompt + example_long\n",
    "get_responses(dat_30, prompt_list_5, 450, \"role_detailed_context_ex_30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a73a81f9-4755-4ffb-81b2-ee60e0f3d2eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Story prompt\n",
    "prompt_list_6 = story_prompt\n",
    "get_responses(dat_30, prompt_list_6, 450, \"story_prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b0cfbcd0-10e2-4fed-a90c-033123ba4b5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Story prompt + example\n",
    "prompt_list_7 = story_prompt + example_long\n",
    "get_responses(dat_30, prompt_list_7, 450, \"story_prompt_ex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83469e22-0417-4aae-8bab-a202309c75de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
